<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Activities on Mengtao (Tomy) Lyuï½œå•å­ŸéŸ¬</title>
    <link>https://Mengtao-Lyu.github.io/activities/</link>
    <description>Recent content in Activities on Mengtao (Tomy) Lyuï½œå•å­ŸéŸ¬</description>
    <generator>Hugo -- 0.147.8</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Nov 2025 19:35:25 -0500</lastBuildDate>
    <atom:link href="https://Mengtao-Lyu.github.io/activities/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>I have received the 2025 IEA/Kingfar Student Award</title>
      <link>https://Mengtao-Lyu.github.io/activities/ieastudent/</link>
      <pubDate>Fri, 28 Nov 2025 19:35:25 -0500</pubDate>
      <guid>https://Mengtao-Lyu.github.io/activities/ieastudent/</guid>
      <description> Iâ€™m deeply honored and thrilled to share that Iâ€™ve received the 2025 IEA/Kingfar Student Award for Research in Human Factors and Ergonomics! This recognition means so much to me as it celebrates the work completed during my PhD journey.
Iâ€™m energized to continue my research in Human Factors, Human-AI Teaming, and related areas, and I look forward to contributing to this vibrant research community.
Award Certificate
</description>
    </item>
    <item>
      <title>My paper has been accepted by International Journal of Human-Computer Studies</title>
      <link>https://Mengtao-Lyu.github.io/activities/ijhcs-2025/</link>
      <pubDate>Sat, 13 Sep 2025 20:06:10 -0400</pubDate>
      <guid>https://Mengtao-Lyu.github.io/activities/ijhcs-2025/</guid>
      <description> Do you need help? Identifying and responding to pilotsâ€™ troubleshooting through eye-tracking and Large Language Model In this study, we introduce an innovative approach that tokenizes eye-tracking data into Visual Attention Matrices (VAMs) and integrates them with Large Language Models to identify and respond to pilotsâ€™ troubleshooting activities in real-time. This represents one of the early works combining eye-tracking data with LLMs for adaptive aviation support systems. The method addresses two key challenges: capturing the complex troubleshooting behaviors of actively engaged (In-the-Loop) pilots, and effectively processing non-semantic eye-tracking data using LLM technology. Graphical Abstract
</description>
    </item>
    <item>
      <title>Farewell ATMRI, thanks for the wonderfull memories â¤ï¸</title>
      <link>https://Mengtao-Lyu.github.io/activities/atmri/</link>
      <pubDate>Tue, 09 Sep 2025 09:11:37 +0800</pubDate>
      <guid>https://Mengtao-Lyu.github.io/activities/atmri/</guid>
      <description> I am deeply grateful to have met such a great team full of excellent brains and warm hearts As 5th Sep marks my final day at ATMRI, I wanted to take a moment to express my heartfelt gratitude to the team for making my time here so meaningful and rewarding. While Iâ€™m excited about the opportunities ahead, I will miss the time we spend together at ATMRI. ğŸ’• The wonderful MSP team
</description>
    </item>
    <item>
      <title>I have officially graduated from The Hong Kong Polytechnic University (PolyU) on 10th May 2025</title>
      <link>https://Mengtao-Lyu.github.io/activities/grad/</link>
      <pubDate>Thu, 05 Jun 2025 13:49:05 +0800</pubDate>
      <guid>https://Mengtao-Lyu.github.io/activities/grad/</guid>
      <description> Feeling incredibly proud and grateful to have been able to complete my PhD at PolyU! I feel fortunate to have been able to work with such a talented team and to have been able to learn so much. Heartful thanks to my amazing supervisors, Dr. Fan Li and Dr. Gangyan Xu, for therir unwavering guidence and support. And a huge credit to my lovely teammates in the SHINE group, a terrific research team fulled with laughters and inspiring minds ğŸ«¶ğŸ«¶ @Congregation | with President, Prof. Jin-Guang Teng
</description>
    </item>
    <item>
      <title>I have successfully defended my PhD theis on 23rd Jan 2025</title>
      <link>https://Mengtao-Lyu.github.io/activities/viva/</link>
      <pubDate>Sat, 22 Feb 2025 15:46:12 +0800</pubDate>
      <guid>https://Mengtao-Lyu.github.io/activities/viva/</guid>
      <description> Thanks to all the members of examaination board, and my friends came to support me! 2022.01.03ï½2025.01.23ğŸ“ 3 years &amp; 20 days It was an exhilarating journey, filled with unexpected twists and frustrations Reaching a milestone, ready to move towards a more challenging and exciting future ğŸ’ªğŸ» PhD Defense
</description>
    </item>
    <item>
      <title></title>
      <link>https://Mengtao-Lyu.github.io/activities/hi-onboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://Mengtao-Lyu.github.io/activities/hi-onboard/</guid>
      <description>sure&#43;&#43;&#43; date = â€˜2025-09-16T09:05:22-04:00â€™ draft = false hidden = false title = â€œIâ€™m happy to share that Iâ€™m starting a new position as Postdoctoral Fellow at the HI Labâ€ &#43;&#43;&#43;
I have joined the Hybrid Intelligence (HI) Lab directed by Mengyao Li on 15 Sep Iâ€™m thrilled to be part of a group dedicated to advancing human-AI collaboration and understanding how we can achieve better outcomes together than either humans or machines can alone. I look forward to this exciting new chapter in my academic journey.ğŸš€ (Chinese cuisines here in Atlanta are amazing as these team fellows ğŸ˜†) Say Hi to the HI Lab members
</description>
    </item>
  </channel>
</rss>
