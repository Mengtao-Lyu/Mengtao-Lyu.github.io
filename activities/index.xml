<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Activities on Mengtao (Tomy) Lyuï½œå•å­ŸéŸ¬</title>
    <link>https://Mengtao-Lyu.github.io/activities/</link>
    <description>Recent content in Activities on Mengtao (Tomy) Lyuï½œå•å­ŸéŸ¬</description>
    <generator>Hugo -- 0.147.8</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 13 Sep 2025 20:06:10 -0400</lastBuildDate>
    <atom:link href="https://Mengtao-Lyu.github.io/activities/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>My paper has been accepted by International Journal of Human-Computer Studies</title>
      <link>https://Mengtao-Lyu.github.io/activities/ijhcs-2025/</link>
      <pubDate>Sat, 13 Sep 2025 20:06:10 -0400</pubDate>
      <guid>https://Mengtao-Lyu.github.io/activities/ijhcs-2025/</guid>
      <description> Do you need help? Identifying and responding to pilotsâ€™ troubleshooting through eye-tracking and Large Language Model In this study, we introduce an innovative approach that tokenizes eye-tracking data into Visual Attention Matrices (VAMs) and integrates them with Large Language Models to identify and respond to pilotsâ€™ troubleshooting activities in real-time. This represents one of the early works combining eye-tracking data with LLMs for adaptive aviation support systems. The method addresses two key challenges: capturing the complex troubleshooting behaviors of actively engaged (In-the-Loop) pilots, and effectively processing non-semantic eye-tracking data using LLM technology. Graphical Abstract
</description>
    </item>
    <item>
      <title>Farewell ATMRI, thanks for the wonderfull memories â¤ï¸</title>
      <link>https://Mengtao-Lyu.github.io/activities/atmri/</link>
      <pubDate>Tue, 09 Sep 2025 09:11:37 +0800</pubDate>
      <guid>https://Mengtao-Lyu.github.io/activities/atmri/</guid>
      <description> I am deeply grateful to have met such a great team full of excellent brains and warm hearts As 5th Sep marks my final day at ATMRI, I wanted to take a moment to express my heartfelt gratitude to the team for making my time here so meaningful and rewarding. While Iâ€™m excited about the opportunities ahead, I will miss the time we spend together at ATMRI. ğŸ’• The wonderful MSP team
</description>
    </item>
    <item>
      <title>I have officially graduated from The Hong Kong Polytechnic University (PolyU) on 10th May 2025</title>
      <link>https://Mengtao-Lyu.github.io/activities/grad/</link>
      <pubDate>Thu, 05 Jun 2025 13:49:05 +0800</pubDate>
      <guid>https://Mengtao-Lyu.github.io/activities/grad/</guid>
      <description> Feeling incredibly proud and grateful to have been able to complete my PhD at PolyU! I feel fortunate to have been able to work with such a talented team and to have been able to learn so much. Heartful thanks to my amazing supervisors, Dr. Fan Li and Dr. Gangyan Xu, for therir unwavering guidence and support. And a huge credit to my lovely teammates in the SHINE group, a terrific research team fulled with laughters and inspiring minds ğŸ«¶ğŸ«¶ @Congregation | with President, Prof. Jin-Guang Teng
</description>
    </item>
    <item>
      <title>I have successfully defended my PhD theis on 23rd Jan 2025</title>
      <link>https://Mengtao-Lyu.github.io/activities/viva/</link>
      <pubDate>Sat, 22 Feb 2025 15:46:12 +0800</pubDate>
      <guid>https://Mengtao-Lyu.github.io/activities/viva/</guid>
      <description> Thanks to all the members of examaination board, and my friends came to support me! 2022.01.03ï½2025.01.23ğŸ“ 3 years &amp; 20 days It was an exhilarating journey, filled with unexpected twists and frustrations Reaching a milestone, ready to move towards a more challenging and exciting future ğŸ’ªğŸ» PhD Defense
</description>
    </item>
  </channel>
</rss>
